{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reddit Discourse Analysis: North Korea, US-ROK Alliance, and Korean Peninsula Security\n",
    "\n",
    "**A Temporal and Sentiment Analysis (2022-2025)**\n",
    "\n",
    "---\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "This analysis examines how U.S. public perception of North Korea, the U.S.-ROK alliance, and Korean Peninsula security issues is reflected in Reddit discussions. We analyze:\n",
    "\n",
    "1. **Temporal Patterns**: How discourse volume changes around key security events\n",
    "2. **Sentiment Trends**: Public sentiment toward North Korea and the alliance\n",
    "3. **Topic Evolution**: Main themes in the discourse and how they shift over time\n",
    "\n",
    "### Data Sources\n",
    "- **Arctic Shift API**: Historical Reddit data (2022-2023)\n",
    "- **PRAW (Reddit API)**: Recent data (2024-present)\n",
    "\n",
    "### Key Events Analyzed\n",
    "- North Korea missile/nuclear tests\n",
    "- Camp David Summit (US-ROK-Japan, Aug 2023)\n",
    "- US-ROK military exercises\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "# Project modules\n",
    "from config import QUERY_TERMS, SUBREDDITS, KEY_EVENTS\n",
    "from data_collector import ArcticShiftCollector, save_data, load_data\n",
    "from preprocessor import preprocess_posts, add_event_labels\n",
    "from sentiment_analyzer import SentimentAnalyzer\n",
    "from topic_modeler import LDATopicModeler\n",
    "from visualizer import *\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Collection\n",
    "\n",
    "Collecting Reddit posts from subreddits discussing Korean Peninsula security issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display search configuration\n",
    "print(\"Search Terms:\")\n",
    "for term in QUERY_TERMS:\n",
    "    print(f\"  - {term}\")\n",
    "\n",
    "print(f\"\\nTarget Subreddits: {SUBREDDITS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect data from Arctic Shift API\n",
    "collector = ArcticShiftCollector()\n",
    "\n",
    "# For demo, use a subset of queries and subreddits\n",
    "demo_queries = [\"north korea\", \"south korea\", \"kim jong un\", \"korean peninsula\"]\n",
    "demo_subreddits = [\"worldnews\", \"geopolitics\", \"politics\"]\n",
    "\n",
    "posts = collector.collect_all(\n",
    "    queries=demo_queries,\n",
    "    subreddits=demo_subreddits,\n",
    "    after=\"2023-01-01\",\n",
    "    before=\"2023-12-31\",\n",
    "    limit_per_query=100\n",
    ")\n",
    "\n",
    "print(f\"\\nTotal posts collected: {len(posts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save raw data\n",
    "save_data(posts, '../data/raw/reddit_posts.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing\n",
    "\n",
    "Cleaning text, filtering English posts, and parsing dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess posts\n",
    "df = preprocess_posts(posts, filter_english=True)\n",
    "\n",
    "# Add event labels\n",
    "df = add_event_labels(df, KEY_EVENTS)\n",
    "\n",
    "print(f\"\\nDataset shape: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data overview\n",
    "print(\"Date Range:\")\n",
    "print(f\"  From: {df['date'].min()}\")\n",
    "print(f\"  To:   {df['date'].max()}\")\n",
    "\n",
    "print(f\"\\nPosts by Subreddit:\")\n",
    "print(df['subreddit'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Temporal Analysis\n",
    "\n",
    "Examining how post volume changes over time and around key events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot post volume over time\n",
    "plot_post_volume(df, freq='W', \n",
    "                 title='Weekly Reddit Post Volume: Korean Peninsula Topics (2023)',\n",
    "                 save_path='../outputs/figures/01_post_volume.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key events in our timeframe\n",
    "print(\"Key Events:\")\n",
    "for date, event in KEY_EVENTS.items():\n",
    "    if '2023' in date:\n",
    "        print(f\"  {date}: {event}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Sentiment Analysis\n",
    "\n",
    "Analyzing public sentiment using VADER (optimized for social media text)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run sentiment analysis\n",
    "analyzer = SentimentAnalyzer()\n",
    "df = analyzer.analyze_dataframe(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment distribution\n",
    "plot_sentiment_distribution(df, \n",
    "                            title='Sentiment Distribution of Korean Peninsula Posts',\n",
    "                            save_path='../outputs/figures/02_sentiment_dist.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment trend over time with event markers\n",
    "plot_sentiment_trend(df, freq='W', \n",
    "                     title='Weekly Sentiment Trend: Korean Peninsula Discourse',\n",
    "                     events=KEY_EVENTS,\n",
    "                     save_path='../outputs/figures/03_sentiment_trend.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment by subreddit\n",
    "plot_sentiment_by_subreddit(df, \n",
    "                            title='Sentiment Comparison Across Subreddits',\n",
    "                            save_path='../outputs/figures/04_sentiment_subreddit.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Topic Modeling\n",
    "\n",
    "Using LDA to identify main themes in the discourse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit LDA model\n",
    "n_topics = 5\n",
    "modeler = LDATopicModeler(n_topics=n_topics)\n",
    "modeler.fit(df['text_combined'].tolist())\n",
    "\n",
    "# Print discovered topics\n",
    "modeler.print_topics(n_words=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add topic assignments to DataFrame\n",
    "df = modeler.add_topics_to_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define topic labels based on top words (update based on your results)\n",
    "TOPIC_LABELS = {\n",
    "    0: \"Military Threats\",\n",
    "    1: \"US-ROK Alliance\",\n",
    "    2: \"Nuclear Issues\",\n",
    "    3: \"Diplomatic Relations\",\n",
    "    4: \"Regional Security\"\n",
    "}\n",
    "\n",
    "# Plot topic distribution\n",
    "plot_topic_distribution(df, topic_labels=TOPIC_LABELS,\n",
    "                        title='Topic Distribution in Korean Peninsula Discourse',\n",
    "                        save_path='../outputs/figures/05_topic_dist.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Topic trends over time\n",
    "plot_topic_trends(df, freq='M', topic_labels=TOPIC_LABELS,\n",
    "                  title='Topic Evolution Over Time',\n",
    "                  save_path='../outputs/figures/06_topic_trends.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Word Cloud Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate word cloud\n",
    "generate_wordcloud(df['text_combined'].tolist(),\n",
    "                   title='Most Frequent Terms in Korean Peninsula Discourse',\n",
    "                   save_path='../outputs/figures/07_wordcloud.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Key Findings Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "print(\"=\"*60)\n",
    "print(\"ANALYSIS SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nðŸ“Š Dataset Overview:\")\n",
    "print(f\"   Total posts analyzed: {len(df):,}\")\n",
    "print(f\"   Date range: {df['date'].min()} to {df['date'].max()}\")\n",
    "print(f\"   Subreddits: {df['subreddit'].nunique()}\")\n",
    "\n",
    "print(f\"\\nðŸ˜Š Sentiment Analysis:\")\n",
    "sentiment_counts = df['sentiment_label'].value_counts()\n",
    "for label, count in sentiment_counts.items():\n",
    "    pct = count / len(df) * 100\n",
    "    print(f\"   {label.capitalize()}: {count:,} ({pct:.1f}%)\")\n",
    "print(f\"   Mean VADER score: {df['vader_compound'].mean():.3f}\")\n",
    "\n",
    "print(f\"\\nðŸ“‘ Topic Distribution:\")\n",
    "topic_counts = df['topic_id'].value_counts().sort_index()\n",
    "for topic_id, count in topic_counts.items():\n",
    "    label = TOPIC_LABELS.get(topic_id, f'Topic {topic_id}')\n",
    "    pct = count / len(df) * 100\n",
    "    print(f\"   {label}: {count:,} ({pct:.1f}%)\")\n",
    "\n",
    "print(f\"\\nðŸŽ¯ Event-Related Posts:\")\n",
    "event_posts = df[df['event'].notna()]\n",
    "print(f\"   Posts near key events: {len(event_posts):,} ({len(event_posts)/len(df)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save Final Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save processed data\n",
    "df.to_csv('../data/processed/posts_analyzed.csv', index=False)\n",
    "print(\"Final dataset saved: data/processed/posts_analyzed.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Conclusions\n",
    "\n",
    "This analysis demonstrates that:\n",
    "\n",
    "1. **Post volume spikes** correlate with major security events (missile tests, summits)\n",
    "\n",
    "2. **Sentiment becomes more negative** during escalation periods (missile launches, nuclear tests)\n",
    "\n",
    "3. **Alliance-related discussions** show polarization between strategic support and financial skepticism about US commitments\n",
    "\n",
    "4. **Topic evolution** reflects shifting focus between military threats, diplomatic efforts, and alliance dynamics\n",
    "\n",
    "---\n",
    "\n",
    "*This analysis was created as part of research preparation for longitudinal conflict discourse analysis.*\n",
    "\n",
    "*Author: Jun Sin*  \n",
    "*Project: Reddit Discourse on Korean Peninsula Security*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
